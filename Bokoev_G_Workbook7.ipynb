{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.datasets import load_digits, load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, weights, bias):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "        \n",
    "    def feedforward(self, inputs):\n",
    "        total = np.dot(self.weights, inputs) + self.bias\n",
    "        \n",
    "        return sigmoid(total)\n",
    "\n",
    "class NeuralNetwork:\n",
    "    '''\n",
    "    Данные нейросети:\n",
    "        - три входа (x1, x2, x3)\n",
    "        - три нейрона в скрытых слоях (h1, h2, h3)\n",
    "        - выход (о1)\n",
    "    Нейроны имеют идентичные веса и пороги:\n",
    "        - w = [0.5, 0.5, 0.5]\n",
    "        - b = 0\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        weights = np.array([.5, .5, .5])\n",
    "        bias = 0\n",
    "\n",
    "        self.h1 = Neuron(weights, bias)\n",
    "        self.h2 = Neuron(weights, bias)\n",
    "        self.h3 = Neuron(weights, bias)\n",
    "        \n",
    "        self.o1 = Neuron(weights, bias)\n",
    "        \n",
    "    def feedforward(self, x):\n",
    "        out_h1 = self.h1.feedforward(x)\n",
    "        out_h2 = self.h2.feedforward(x)\n",
    "        out_h3 = self.h3.feedforward(x)\n",
    "\n",
    "        out_o1 = self.o1.feedforward(np.array([out_h1, out_h2, out_h3]))\n",
    "        \n",
    "        return out_o1\n",
    "    \n",
    "network = NeuralNetwork()\n",
    "x = np.array([2, 3, 4])\n",
    "\n",
    "print(network.feedforward(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, weights, bias):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "        \n",
    "    def feedforward(self, inputs):\n",
    "        total = np.dot(self.weights, inputs) + self.bias\n",
    "        \n",
    "        return sigmoid(total)\n",
    "\n",
    "class NeuralNetwork:\n",
    "    '''\n",
    "    Данные нейросети:\n",
    "        - два входа (x1, x2)\n",
    "        - два нейрона в скрытых слоях (h1, h2)\n",
    "        - два выхода (о1, o2)\n",
    "    Нейроны имеют идентичные веса и пороги:\n",
    "        - w = [1, 0]\n",
    "        - b = 1\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        weights = np.array([1, 0])\n",
    "        bias = 1\n",
    "\n",
    "        self.h1 = Neuron(weights, bias)\n",
    "        self.h2 = Neuron(weights, bias)\n",
    "\n",
    "        self.o1 = Neuron(weights, bias)\n",
    "        self.o2 = Neuron(weights, bias)\n",
    "        \n",
    "    def feedforward(self, x):\n",
    "        out_h1 = self.h1.feedforward(x)\n",
    "        out_h2 = self.h2.feedforward(x)\n",
    "\n",
    "        out_o1 = self.o1.feedforward(np.array([out_h1, out_h2]))\n",
    "        out_o2 = self.o2.feedforward(np.array([out_h1, out_h2]))\n",
    "        \n",
    "        return out_o1, out_o2\n",
    "    \n",
    "network = NeuralNetwork()\n",
    "x = np.array([2, 3])\n",
    "\n",
    "print(*network.feedforward(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def relu(x):\n",
    "    return max(0, x)\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, weights, bias):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "        \n",
    "    def feedforward_sigmoid(self, inputs):\n",
    "        total = np.dot(self.weights, inputs) + self.bias\n",
    "        \n",
    "        return sigmoid(total)\n",
    "    \n",
    "    def feedforward_tanh(self, inputs):\n",
    "        total = np.dot(self.weights, inputs) + self.bias\n",
    "        \n",
    "        return tanh(total)\n",
    "    \n",
    "    def feedforward_relu(self, inputs):\n",
    "        total = np.dot(self.weights, inputs) + self.bias\n",
    "        \n",
    "        return relu(total)\n",
    "\n",
    "class NeuralNetwork:\n",
    "    '''\n",
    "    Данные нейросети:\n",
    "        - три входа (x1, x2, x3)\n",
    "        - три нейрона в скрытых слоях (h1, h2, h3)\n",
    "        - выход (о1)\n",
    "    Нейроны имеют идентичные веса и пороги:\n",
    "        - w = [0.5, 0.5, 0.5]\n",
    "        - b = 0\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        weights = np.array([.5, .5, .5])\n",
    "        bias = 0\n",
    "\n",
    "        self.h1 = Neuron(weights, bias)\n",
    "        self.h2 = Neuron(weights, bias)\n",
    "        self.h3 = Neuron(weights, bias)\n",
    "    \n",
    "        self.o1 = Neuron(weights, bias)\n",
    "        \n",
    "    def feedforward_sigmoid(self, x):\n",
    "        out_h1 = self.h1.feedforward_sigmoid(x)\n",
    "        out_h2 = self.h2.feedforward_sigmoid(x)\n",
    "        out_h3 = self.h3.feedforward_sigmoid(x)\n",
    "        \n",
    "        out_o1 = self.o1.feedforward_sigmoid(np.array([out_h1, out_h2, out_h3]))\n",
    "        \n",
    "        return out_o1\n",
    "    \n",
    "    def feedforward_tanh(self, x):\n",
    "        out_h1 = self.h1.feedforward_tanh(x)\n",
    "        out_h2 = self.h2.feedforward_tanh(x)\n",
    "        out_h3 = self.h3.feedforward_tanh(x)\n",
    "        \n",
    "        out_o1 = self.o1.feedforward_tanh(np.array([out_h1, out_h2, out_h3]))\n",
    "        \n",
    "        return out_o1\n",
    "    \n",
    "    def feedforward_relu(self, x):\n",
    "        out_h1 = self.h1.feedforward_relu(x)\n",
    "        out_h2 = self.h2.feedforward_relu(x)\n",
    "        out_h3 = self.h3.feedforward_relu(x)\n",
    "        \n",
    "        out_o1 = self.o1.feedforward_relu(np.array([out_h1, out_h2, out_h3]))\n",
    "        \n",
    "        return out_o1\n",
    "    \n",
    "network = NeuralNetwork()\n",
    "x = np.array([2, 3, 4])\n",
    "\n",
    "print(f'Sigmoid: {network.feedforward_sigmoid(x)}\\nTanh: {network.feedforward_tanh(x)}\\nReLU: {network.feedforward_relu(x)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url1 = r'https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv'\n",
    "url2 = r'https://raw.githubusercontent.com/AnnaShestova/salary-years-simple-linear-regression/master/Salary_Data.csv'\n",
    "\n",
    "dataset1 = pd.read_csv(url1)\n",
    "dataset2 = pd.read_csv(url2)\n",
    "\n",
    "digits = load_digits()\n",
    "\n",
    "X_digits, Y_digits = digits.data, digits.target\n",
    "\n",
    "X_boston, Y_boston = dataset2.iloc[:, :], dataset2.iloc[:, 1]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_digits, Y_digits, train_size=0.8, test_size=0.2, stratify=Y_digits, random_state=123)\n",
    "print('Train/Test Sizes: ', X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)\n",
    "print('\\n', X_train, '\\n', Y_train)\n",
    "\n",
    "mlp_classifier = MLPClassifier(random_state=123)\n",
    "mlp_classifier.fit(X_train, Y_train)\n",
    "\n",
    "Y_preds = mlp_classifier.predict(X_test)\n",
    "\n",
    "print(Y_preds[:15])\n",
    "print(Y_test[:15])\n",
    "print('Test Accuracy: %.3f' % mlp_classifier.score(X_test, Y_test))\n",
    "print('Training Accuracy: %.3f' % mlp_classifier.score(X_train, Y_train))\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(Y_test, Y_preds):\n",
    "    conf_mat = confusion_matrix(Y_test, Y_preds)\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    plt.matshow(conf_mat, cmap=plt.cm.Blues, fignum=1)\n",
    "    plt.yticks(range(3), range(3))\n",
    "    plt.xticks(range(3), range(3))\n",
    "    plt.colorbar()\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            plt.text(i - 0.2, j + 0.1, str(conf_mat[j, i]), color='tab:red')\n",
    "\n",
    "plot_confusion_matrix(Y_test, mlp_classifier.predict(X_test))\n",
    "\n",
    "print(\"Loss: \", mlp_classifier.loss_)\n",
    "print(\"Number of Coefs: \", len(mlp_classifier.coefs_))\n",
    "print(\"Number of Intercepts: \", mlp_classifier.intercepts_)\n",
    "print(\"Number of Iterations for Which Estimator Ran: \", mlp_classifier.n_iter_)\n",
    "print(\"Name of Output Layer Activation Function: \", mlp_classifier.out_activation_)\n",
    "\n",
    "mlp_regressor = MLPRegressor(random_state=123)\n",
    "mlp_regressor.fit(X_train, Y_train)\n",
    "\n",
    "Y_preds = mlp_regressor.predict(X_test)\n",
    "\n",
    "print(Y_preds[:10])\n",
    "print(Y_test[:10])\n",
    "\n",
    "print('Test R^2 Score: %.3f' % mlp_regressor.score(X_test, Y_test))\n",
    "print('Training R^2 Score: %.3f' % mlp_regressor.score(X_train, Y_train))\n",
    "\n",
    "print(\"Loss: \", mlp_regressor.loss_)\n",
    "print(\"Number of Coefs: \", len(mlp_regressor.coefs_))\n",
    "print(\"Number of Intercepts: \", mlp_regressor.intercepts_)\n",
    "print(\"Number of Iterations for Which Estamator Ran: \", mlp_regressor.n_iter_)\n",
    "print(\"Name of Output Layer Activation Function: \", mlp_regressor.out_activation_)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8b3424640b024d7c772b21f95b266b3dcac58ebbdc4a7b56b4c4d43b35939d7f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
